@misc{Blanco2024,
   author = {Omar Anoud Blanco and Gabriel Torregrosa and Cortés Jordi and García Ojalvo},
   month = {7},
   title = {Autoencoder analysis of bacterial growth},
   year = {2024},
}
@article{,
   abstract = {The aim of this study was to evaluate the suitability of several mathematical functions for describing microbial growth curves. The nonlinear functions used were: three-phase linear, logistic, Gompertz, Von Bertalanffy, Richards, Morgan, Weibull, France and Baranyi. Two data sets were used, one comprising 21 growth curves of different bacterial and fungal species in which growth was expressed as optical density units, and one comprising 34 curves of colony forming units counted on plates of Yersinia enterocolitica grown under different conditions of pH, temperature and CO2 (time-constant conditions for each culture). For both sets, curves were selected to provide a wide variety of shapes with different growth rates and lag times. Statistical criteria used to evaluate model performance were analysis of residuals (residual distribution, bias factor and serial correlation) and goodness-of-fit (residual mean square, accuracy factor, extra residual variance F-test, and Akaike's information criterion). The models showing the best overall performance were the Baranyi, three-phase linear, Richards and Weibull models. The goodness-of-fit attained with other models can be considered acceptable, but not as good as that reached with the best four models. Overall, the Baranyi model showed the best behaviour for the growth curves studied according to a variety of criteria. The Richards model was the best-fitting optical density data, whereas the three-phase linear showed some limitations when fitting these curves, despite its consistent performance when fitting plate counts. Our results indicate that the common use of the Gompertz model to describe microbial growth should be reconsidered critically, as the Baranyi, three-phase linear, Richards and Weibull models showed a significantly superior ability to fit experimental data than the extensively used Gompertz. © 2004 Elsevier B.V. All rights reserved.},
   author = {S. López and M. Prieto and J. Dijkstra and M. S. Dhanoa and J. France},
   doi = {10.1016/j.ijfoodmicro.2004.03.026},
   issn = {01681605},
   issue = {3},
   journal = {International Journal of Food Microbiology},
   keywords = {Growth curves,Mathematical models,Microbial growth,Nonlinear equations,Sigmoidal functions},
   month = {11},
   pages = {289-300},
   pmid = {15454319},
   title = {Statistical evaluation of mathematical models for microbial growth},
   volume = {96},
   year = {2004},
}
@misc{Cranmer2023,
   abstract = {PySR 3 is an open-source library for practical symbolic regression, a type of machine learning which aims to discover human-interpretable symbolic models. PySR was developed to democra-tize and popularize symbolic regression for the sciences, and is built on a high-performance distributed backend, a flexible search algorithm, and interfaces with several deep learning packages. PySR's internal search algorithm is a multi-population evolutionary algorithm, which consists of a unique evolve-simplify-optimize loop, designed for optimization of unknown scalar constants in newly-discovered empirical expressions. PySR's backend is an extremely optimized Julia library SymbolicRegression.jl 4 , which can be used directly from Julia. It is capable of fusing user-defined operators into SIMD kernels at runtime, performing automatic differentiation, and distributing populations of expressions to thousands of cores across a cluster. In describing this software, we also introduce a new benchmark, "EmpiricalBench," to quantify the applicability of symbolic regression algorithms in science. This benchmark measures recovery of historical empirical equations from original and synthetic datasets.},
   author = {Miles Cranmer},
   title = {Interpretable Machine Learning for Science with PySR and SymbolicRegression.jl},
   year = {2023},
}
@article{Raissi2019,
   abstract = {We introduce physics-informed neural networks – neural networks that are trained to solve supervised learning tasks while respecting any given laws of physics described by general nonlinear partial differential equations. In this work, we present our developments in the context of solving two main classes of problems: data-driven solution and data-driven discovery of partial differential equations. Depending on the nature and arrangement of the available data, we devise two distinct types of algorithms, namely continuous time and discrete time models. The first type of models forms a new family of data-efficient spatio-temporal function approximators, while the latter type allows the use of arbitrarily accurate implicit Runge–Kutta time stepping schemes with unlimited number of stages. The effectiveness of the proposed framework is demonstrated through a collection of classical problems in fluids, quantum mechanics, reaction–diffusion systems, and the propagation of nonlinear shallow-water waves.},
   author = {M. Raissi and P. Perdikaris and G. E. Karniadakis},
   doi = {10.1016/j.jcp.2018.10.045},
   issn = {10902716},
   journal = {Journal of Computational Physics},
   keywords = {Data-driven scientific computing,Machine learning,Nonlinear dynamics,Predictive modeling,Runge–Kutta methods},
   month = {2},
   pages = {686-707},
   publisher = {Academic Press Inc.},
   title = {Physics-informed neural networks: A deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations},
   volume = {378},
   year = {2019},
}
@misc{Mehta2019,
   abstract = {Machine Learning (ML) is one of the most exciting and dynamic areas of modern research and application. The purpose of this review is to provide an introduction to the core concepts and tools of machine learning in a manner easily understood and intuitive to physicists. The review begins by covering fundamental concepts in ML and modern statistics such as the bias–variance tradeoff, overfitting, regularization, generalization, and gradient descent before moving on to more advanced topics in both supervised and unsupervised learning. Topics covered in the review include ensemble models, deep learning and neural networks, clustering and data visualization, energy-based models (including MaxEnt models and Restricted Boltzmann Machines), and variational methods. Throughout, we emphasize the many natural connections between ML and statistical physics. A notable aspect of the review is the use of Python Jupyter notebooks to introduce modern ML/statistical packages to readers using physics-inspired datasets (the Ising Model and Monte-Carlo simulations of supersymmetric decays of proton–proton collisions). We conclude with an extended outlook discussing possible uses of machine learning for furthering our understanding of the physical world as well as open problems in ML where physicists may be able to contribute.},
   author = {Pankaj Mehta and Marin Bukov and Ching Hao Wang and Alexandre G.R. Day and Clint Richardson and Charles K. Fisher and David J. Schwab},
   doi = {10.1016/j.physrep.2019.03.001},
   issn = {03701573},
   journal = {Physics Reports},
   month = {5},
   pages = {1-124},
   publisher = {Elsevier B.V.},
   title = {A high-bias, low-variance introduction to Machine Learning for physicists},
   volume = {810},
   year = {2019},
}
@article{Prokop2024,
   abstract = {Many dynamical systems exhibit oscillatory behavior that can be modeled with differential equations. Recently, these equations have increasingly been derived through data-driven methods, including the transparent technique known as Sparse Identification of Nonlinear Dynamics (SINDy). This paper illustrates the importance of accurately determining the system's limit cycle position in phase space for identifying sparse and effective models. We introduce a method for identifying the limit cycle position and the system's nullclines by applying SINDy to datasets adjusted with various offsets. This approach is evaluated using three criteria: model complexity, coefficient of determination, and generalization error. We applied this method to several models: the oscillatory FitzHugh-Nagumo model, a more complex model consisting of two coupled cubic differential equations with a single stable state, and a multistable model of glycolytic oscillations. Our results confirm that incorporating detailed information about the limit cycle in phase space enhances the accuracy of model identification in oscillatory systems.e space can improve the success of model identification efforts in oscillatory systems.},
   author = {Bartosz Prokop and Nikita Frolov and Lendert Gelens},
   doi = {10.1063/5.0199311},
   month = {2},
   title = {Enhancing model identification with SINDy via nullcline reconstruction},
   url = {http://arxiv.org/abs/2402.03168 http://dx.doi.org/10.1063/5.0199311},
   year = {2024},
}
@article{Zhang2024,
   abstract = {Misfolded tau proteins play a critical role in the progression and pathology of Alzheimer's disease. Recent studies suggest that the spatio-temporal pattern of misfolded tau follows a reaction–diffusion type equation. However, the precise mathematical model and parameters that characterize the progression of misfolded protein across the brain remain incompletely understood. Here, we use deep learning and artificial intelligence to discover a mathematical model for the progression of Alzheimer's disease using longitudinal tau positron emission tomography from the Alzheimer's Disease Neuroimaging Initiative database. Specifically, we integrate physics informed neural networks (PINNs) and symbolic regression to discover a reaction–diffusion type partial differential equation for tau protein misfolding and spreading. First, we demonstrate the potential of our model and parameter discovery on synthetic data. Then, we apply our method to discover the best model and parameters to explain tau imaging data from 46 individuals who are likely to develop Alzheimer's disease and 30 healthy controls. Our symbolic regression discovers different misfolding models f(c) for two groups, with a faster misfolding for the Alzheimer's group, f(c)=0.23c3−1.34c2+1.11c, than for the healthy control group, f(c)=−c3+0.62c2+0.39c. Our results suggest that PINNs, supplemented by symbolic regression, can discover a reaction–diffusion type model to explain misfolded tau protein concentrations in Alzheimer's disease. We expect our study to be the starting point for a more holistic analysis to provide image-based technologies for early diagnosis, and ideally early treatment of neurodegeneration in Alzheimer's disease and possibly other misfolding-protein based neurodegenerative disorders.},
   author = {Zhen Zhang and Zongren Zou and Ellen Kuhl and George Em Karniadakis},
   doi = {10.1016/j.cma.2023.116647},
   issn = {00457825},
   journal = {Computer Methods in Applied Mechanics and Engineering},
   keywords = {Alzheimer's disease,Misfolded tau protein,Model discovery,PINNs,Symbolic regression,Uncertainty quantification},
   month = {2},
   publisher = {Elsevier B.V.},
   title = {Discovering a reaction–diffusion model for Alzheimer's disease by combining PINNs with symbolic regression},
   volume = {419},
   year = {2024},
}
